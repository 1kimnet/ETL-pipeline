--- original/./etl/pipeline.py
+++ fixed/./etl/pipeline.py
@@ -173,13 +173,15 @@
 
         # ---------- 1. DOWNLOAD & STAGING ---------------------------------
         sources = list(Source.load_all(self.sources_yaml_path))
-<<<<<<< HEAD
+
+
+<< << << < HEAD
         self.logger.info(f"ðŸ“‹ Found sources to process: {len(sources)}")
-=======
+== == == =
         self.logger.info(
             "ðŸ“‹ Found sources to process",
             source_count=len(sources))
->>>>>>> 451a390db650ddc3a12688a44583af8901886af8
+>>>>>> > 451a390db650ddc3a12688a44583af8901886af8
 
         # Create SDE loader for proper source-to-dataset mapping
         from .models import AppConfig, SdeLoader
@@ -193,13 +195,15 @@
 
         # Log concurrent download configuration
         if self.global_cfg.get("enable_concurrent_downloads", True):
-            rest_workers = self.global_cfg.get("concurrent_download_workers", 5)
-            ogc_workers = self.global_cfg.get("concurrent_collection_workers", 3)
+            rest_workers = self.global_cfg.get(
+                "concurrent_download_workers", 5)
+            ogc_workers = self.global_cfg.get(
+                "concurrent_collection_workers", 3)
             file_workers = self.global_cfg.get("concurrent_file_workers", 4)
             self.logger.info(
-<<<<<<< HEAD
+<< << << < HEAD
                 f"ðŸš€ Concurrent downloads enabled: REST={rest_workers}, OGC={ogc_workers}, Files={file_workers} workers"
-=======
+== == == =
                 "ðŸš€ Concurrent downloads enabled: REST=%d, OGC=%d, Files=%d workers",
                 self.global_cfg.get(
                     "concurrent_download_workers",
@@ -210,7 +214,7 @@
                 self.global_cfg.get(
                     "concurrent_file_workers",
                     4),
->>>>>>> 451a390db650ddc3a12688a44583af8901886af8
+>>>>>> > 451a390db650ddc3a12688a44583af8901886af8
             )
         else:
             self.logger.info(
@@ -323,13 +327,13 @@
                 reset_gdb(gdb_path)
             self.logger.info("âœ… Staging GDB reset complete")
         except (ImportError, arcpy.ExecuteError, OSError) as reset_exc:
-<<<<<<< HEAD
+<< << << < HEAD
             self.logger.warning(f"âš ï¸ Failed to reset staging GDB: {reset_exc}")
-=======
+== == == =
             self.logger.warning(
                 "âš ï¸ Failed to reset staging GDB",
                 error=reset_exc)
->>>>>>> 451a390db650ddc3a12688a44583af8901886af8
+>>>>>> > 451a390db650ddc3a12688a44583af8901886af8
             if not self.global_cfg.get("continue_on_failure", True):
                 self.monitor.end_run("failed")
                 raise
--- original/./etl/utils/regression_detector.py
+++ fixed/./etl/utils/regression_detector.py
@@ -384,7 +384,8 @@
             "total_operations_monitored": len(self.performance_data),
             "baselines_established": len(self.baselines),
             "regressions_by_severity": {
-                severity: len([r for r in recent_regressions if r.severity == severity])
+                severity: len(
+                    [r for r in recent_regressions if r.severity == severity])
                 for severity in ["minor", "moderate", "major", "critical"]
             },
             "operation_analysis": operation_analysis,
--- original/./etl/utils/performance_optimizer.py
+++ fixed/./etl/utils/performance_optimizer.py
@@ -125,7 +125,8 @@
                 peak_memory = current
 
         # Start memory monitoring
-        monitor_thread = threading.Thread(target=lambda: monitor_memory(), daemon=True)
+        monitor_thread = threading.Thread(
+            target=lambda: monitor_memory(), daemon=True)
         monitor_thread.start()
 
         try:
@@ -145,7 +146,8 @@
 
             # Trigger garbage collection if memory usage is high
             if self.get_memory_usage() > self.gc_threshold:
-                log.info("ðŸ§¹ High memory usage detected, triggering garbage collection")
+                log.info(
+                    "ðŸ§¹ High memory usage detected, triggering garbage collection")
                 collected = gc.collect()
                 log.debug("Garbage collection freed %d objects", collected)
 
@@ -154,7 +156,8 @@
         current_usage = self.get_memory_usage()
 
         if current_usage > self.memory_threshold:
-            log.info("ðŸ§¹ Memory usage at %.1f%%, optimizing...", current_usage * 100)
+            log.info("ðŸ§¹ Memory usage at %.1f%%, optimizing...",
+                     current_usage * 100)
 
             # Force garbage collection
             collected = gc.collect()
@@ -299,7 +302,8 @@
 
         # Analyze recent performance
         recent_metrics = performance_metrics[-5:]  # Last 5 operations
-        avg_cpu = sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics)
+        avg_cpu = sum(m.cpu_percent for m in recent_metrics) / \
+            len(recent_metrics)
         avg_throughput = sum(m.throughput_items_per_sec for m in recent_metrics) / len(
             recent_metrics
         )
@@ -551,15 +555,17 @@
             return []
 
         total_items = len(items)
-        batch_size = self.calculate_optimal_batch_size(total_items, item_size_mb)
-
-        log.info("ðŸ”„ Processing %d items in batches of %d", total_items, batch_size)
+        batch_size = self.calculate_optimal_batch_size(
+            total_items, item_size_mb)
+
+        log.info("ðŸ”„ Processing %d items in batches of %d",
+                 total_items, batch_size)
 
         results = []
         processed_count = 0
 
         for i in range(0, total_items, batch_size):
-            batch = items[i : i + batch_size]
+            batch = items[i: i + batch_size]
             batch_num = i // batch_size + 1
             total_batches = (total_items + batch_size - 1) // batch_size
 
@@ -586,7 +592,8 @@
                         self.memory_optimizer.optimize_memory_usage()
 
                 except Exception as e:
-                    log.error("Batch %d/%d failed: %s", batch_num, total_batches, e)
+                    log.error("Batch %d/%d failed: %s",
+                              batch_num, total_batches, e)
                     # Continue with next batch rather than failing entirely
                     continue
 
--- original/./etl/utils/adaptive_tuning.py
+++ fixed/./etl/utils/adaptive_tuning.py
@@ -43,8 +43,8 @@
             current_metrics: PerformanceMetrics,
             threshold: float = 0.2) -> bool:
         """Check if current performance is degraded compared to baseline."""
-        duration_increase = (current_metrics.duration - \
-                             self.avg_duration) / self.avg_duration # type: ignore
+        duration_increase = (current_metrics.duration -
+                             self.avg_duration) / self.avg_duration  # type: ignore
         throughput_decrease = (
             self.avg_throughput - current_metrics.throughput_items_per_sec) / self.avg_throughput
 
--- original/./etl/handlers/rest_api.py
+++ fixed/./etl/handlers/rest_api.py
@@ -65,7 +65,8 @@
             expected_exceptions=[Exception],
         )
 
-        log.info("ðŸš€ Initializing RestApiDownloadHandler for source: %s", self.src.name)
+        log.info(
+            "ðŸš€ Initializing RestApiDownloadHandler for source: %s", self.src.name)
 
     @retry_with_backoff()
     def _get_service_metadata(self, service_url: str) -> Optional[Dict[str, Any]]:
@@ -171,11 +172,13 @@
         """Fetches metadata for a specific layer."""
         try:
             params = {"f": "json"}
-            response = self.session.get(layer_url, params=params, timeout=self.timeout)
+            response = self.session.get(
+                layer_url, params=params, timeout=self.timeout)
             response.raise_for_status()
             return response.json()
         except requests.exceptions.RequestException as e:
-            log.error("âŒ Failed to fetch layer metadata from %s: %s", layer_url, e)
+            log.error("âŒ Failed to fetch layer metadata from %s: %s",
+                      layer_url, e)
             return None
 
     def _prepare_query_params(self) -> Dict[str, Any]:
@@ -210,7 +213,8 @@
     ) -> Optional[Dict[str, Any]]:
         """Execute a paginated request and return the JSON payload."""
         try:
-            response_obj = self.session.get(query_url, params=params, timeout=120)
+            response_obj = self.session.get(
+                query_url, params=params, timeout=120)
             response_obj.raise_for_status()
             return response_obj.json()
         except requests.exceptions.RequestException as e:
@@ -295,7 +299,8 @@
         try:
             with open(output_path, "w", encoding="utf-8") as f:
                 json.dump(final_output_data, f, ensure_ascii=False, indent=2)
-            log.info("âœ… %s: %d features", layer_name_sanitized, features_written_total)
+            log.info("âœ… %s: %d features", layer_name_sanitized,
+                     features_written_total)
             log.debug(
                 "ðŸ’¾ Successfully saved %d features for layer %s to %s",
                 features_written_total,
@@ -342,7 +347,8 @@
             if "id" in lyr
         }
 
-<<<<<<< HEAD
+
+<< << << < HEAD
         if configured_layer_ids_from_yaml:
             log.info(
                 "Found explicit layer_ids in config: %s for source '%s'. Processing only these.",
@@ -350,8 +356,9 @@
                 self.src.name,
             )
             if not isinstance(configured_layer_ids_from_yaml, list):
-                configured_layer_ids_from_yaml = [configured_layer_ids_from_yaml]
-=======
+                configured_layer_ids_from_yaml = [
+                    configured_layer_ids_from_yaml]
+== == == =
            if configured_layer_ids_from_yaml:
                 log.info(
                     "Found explicit layer_ids in config: %s for source '%s'. Processing only these.",
@@ -361,17 +368,18 @@
                 if not isinstance(configured_layer_ids_from_yaml, list):
                     configured_layer_ids_from_yaml = [
                         configured_layer_ids_from_yaml]
->>>>>>> 451a390db650ddc3a12688a44583af8901886af8
+>>>>>> > 451a390db650ddc3a12688a44583af8901886af8
 
             for lid_val in configured_layer_ids_from_yaml:
                 lid_str = str(lid_val)
                 layer_detail = metadata_layers_details.get(lid_str)
 
-<<<<<<< HEAD
+<< << << < HEAD
                 if layer_detail:
                     layer_name = layer_detail.get("name", f"layer_{lid_str}")
                     layers_to_iterate_final.append(
-                        {"id": lid_str, "name": layer_name, "metadata": layer_detail}
+                        {"id": lid_str, "name": layer_name,
+                            "metadata": layer_detail}
                     )
                 else:
                     log.warning(
@@ -388,12 +396,13 @@
                             "metadata": None,
                         }
                     )
-=======
+== == == =
                    if layer_detail:
                         layer_name = layer_detail.get(
                             "name", f"layer_{lid_str}")
                         layers_to_iterate_final.append(
-                            {"id": lid_str, "name": layer_name, "metadata": layer_detail}
+                            {"id": lid_str, "name": layer_name,
+                                "metadata": layer_detail}
                         )
                     else:
                         log.warning(
